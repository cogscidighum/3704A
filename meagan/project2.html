<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://fonts.googleapis.com/css?family=Mulish" rel="stylesheet">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.slim.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>
</head>
  <style>
    * {
      box-sizing: border-box;
    }
    header {
      background: #594a4e;
      color: white;
      padding:10px;
    }
    
    a{
      color:#f76083;
    }

    .center{
      text-align: center;
      display: block;
      margin-left: auto;
      margin-right: auto;
    }

    body {
    font-family: 'Mulish';
    background: #ffc6c7;
    color: #594a4e;
    margin-top: 100px;
    margin-bottom: 100px;
    margin-right: 150px;
    margin-left: 80px;
    }

    li{
      margin-top: 10px;
    }

    .margin {margin-bottom: 25px;}

    #backToTop {
    display: none;
    position: fixed;
    bottom: 20px;
    right: 30px;
    z-index: 99;
    font-size: 18px;
    border: none;
    outline: none;
    background-color: #ff8ba7;
    color: #594a4e;
    cursor: pointer;
    padding: 15px;
    border-radius: 4px;
  }

  #backToTop:hover {
    background-color: #f76083;
  }

  </style>
  <header>
      <h1 class="center">Meagan's Webpage</h1>
  </header>
<body>
  <button onclick="topFunction()" id="backToTop" title="Back to Top">Top</button>
  <div class="margin"></div>
  <h2>Table of Contents</h2>
  <ol>
    <li><a href="#abstract">Abstract</a></li>
    <li><a href="#biography">Biography</a></li>
	<li><a href="#actionVII">Data Info</a></li>
    <li><a href="#videoSummary">Video Summaries</a>
		<ul>
			<li><a href="#dangersOfAi">The Dangers of AI is Weirder Than You Think</a></li>
			<li><a href="#canCant">What AI can do - and can't</a></li>
			<li><a href="#forArt">Machine learning failures - for art!</a></li>
			<li><a href="#loveYou">You Look Like a Thing and I Love You</a></li>
			<li><a href="#revolution">TECHTalk Leading the AI/ML Revolution</a></li>
		</ul>
		</li>
    <li><a href="#opinion">My Opinion</a></li>
    <li><a href="#herBlog">Her Blog</a></li>
    <li><a href="#references">References</a></li>
  </ol>
  <div class="margin"></div>
  <h1 class="margin center">Janelle Shane</h1>

  <div class="container-fluid margin">
    <h2 id="abstract">Abstract</h2>
    <p>
      Often in the media, AI is portrayed as dangerous and bent on destroying humanity. However, Janelle Shane offers a different view. She compares the intelligence of AI
      to an earthworm and highlights silly mistakes made by AIs. Her comedic approach helps educate and alliveate people's fears of AI through her <a href="https://www.youtube.com/watch?v=OhCzX0iLnOc">TED Talk</a>, 
      <a href="https://www.aiweirdness.com/">blog</a>, and social media. She is a cognitive digital celebrity scientist as she foucses on AI and evaluates their problem solving skills in relation to typical human responses.
    </p>
  </div>
  
  <div class="container-fluid margin">
    <h2 class="margin" id="biography">Biography</h2>
    <div class="row">
      <div class="col-xs-6 col-sm-4">
        <img src="https://images.squarespace-cdn.com/content/v1/5d62d15300eb5b0001437ac0/1566760058767-QI1E28TSHWM77ZPK4X5J/Janelle_Shane_headshot1_web.jpg?format=2500w" alt="Janelle Shane" width="75%">
      </div>
      <div class="col-xs-6 col-sm-8">
        <p>Janelle Shane is a research scientist in optics. Her work involves creating computer-controlled holograms to study the brain. 
          Additionally, she runs a blog about machine learning called 
          <a href="https://www.aiweirdness.com/">aiweirdness</a>.
          , where she writes about weird things that artificial intellgence comes up with. She conducts experiments that prompts 
          different AI models to generate recipes, paint colours, cat names, candy heart messages, etc. 
          Her work has been featured in New York Times, The Atlantic, WIRED, Popular Science, All Things Considered, and Slate. 
          Furthermore, she was honored as a TED fellow in 2019. I included her TED Talk below, where she explains that AI is more 
          silly than it is dangerous. She has also authored her own book, 
          <a href=https://mybook.to/YouLookLikeAThing>"You Look Like a Thing and I Love You: How AI Works and Why it's Making the World a Weirder Place"</a>.
          Much like her TED talk, in her book she talks about silly solutions that AIs come up with and examines just how intelligent they truly are.
          <br><br>
          Her social media links:
          <a href="https://www.instagram.com/janellecshane/">Instagram</a> |
          <a href="https://twitter.com/JanelleCShane">Twitter</a>
        </p>
      </div>
    </div>
  </div>

  <div class="container-fluid margin">
    <h2 class="margin" id="actionVII">Data Info</h2>
    <div class="row">
      <div class="col margin">
        <p><a href="https://cogscidighum.github.io/3704A/meagan/actionx.html">Action X</a></p>
        <iframe width= "100%" height="350" src="https://cogscidighum.github.io/3704A/meagan/actionx.html" title="acogsphere" ></iframe>
      </div>
      <div class="col margin">
        <p><a href="https://cogscidighum.github.io/3704A/meagan/actionxi.html">Action XI: Part 1</a></p>
        <iframe width= "100%" height="350" src="https://cogscidighum.github.io/3704A/meagan/actionxi.html" title="bcogsphere" ></iframe>
      </div>
      <div class="col margin">
        <p><a href="https://cogscidighum.github.io/3704A/meagan/actionxi_part2.html">Action XI: Part 2</a></p>
        <iframe width= "100%" height="350" src="https://cogscidighum.github.io/3704A/meagan/actionxi_part2.html" title="acbogsphere" ></iframe>
      </div>
    </div>
  </div>

  <div class="container-fluid">
	<h2 class="margin" id="videoSummary">Video Summary</h2>
	<h4 id="dangersOfAi">The Dangers of AI is Weirder Than You Think</h4>
	<iframe width="600" height="350" src="https://www.youtube.com/embed/OhCzX0iLnOc?si=Xao-rA71LYVKk5o6" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
	<p>In this video, Janelle Shane demonstrates that the way we train AI can significantly impact its performance. If we do not provide clear instructions, it tends to product unexpected solutions to problems. One of the examples she provided was an experiment that tasked an AI with navigating an obstacle course in a virtual environment. The expected outcome was that it would create a "body" and use its legs to run across the course. But instead, it made itself into a giant tower. When it toppled over, it reached the end of the obstacle course. Shane likened the intelligence of modern AI to that of an earthworm or even less. Although AI can follow instructions well, it lacks an understanding of what it's doing and what it should be doing. As a result, AI tends to come up with unconventional, and sometimes silly, solutions.
	<br><br>
	Despite the humour, Shane brings up an important point that scientists and other users of artificial intelligence need to mindful of, the importance of giving AI clear instructions. AIs do not think like us as they are not programmed in the same way we are. To better understand AI, we need to think more of how an AI will respond. Additionally, this concept is also important not just in AI, but also in cognitive science. If we want to develop cognitive models that represents our minds, we ought to develop AI that will respond how we would, rather than an obscure, and literal way. This also touches on philosophy, specifically normativity -- how ought the AI act? Do we want it to resemble us, and if so, how should we treat them, - as an object or as a real conscious being?
	</p>

	<div class="margin"></div>

	<h4 id="canCant">What AI can do - and can't</h4>
	<iframe width="600" height="350" src="https://www.youtube.com/embed/NFbJSQIfZrw?si=PqkpXpkHa8G7krvx" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
	<p>Again, Janelle Shane urges the public on the limitations of AI, such that they are not good at solving broad problems. Instead, they excel better on narrow problems. Her reasoning for this is because broad problems tend to leave up more room for the AI to misunderstand the problem, which results in weird solutions. For example, she mentioned an AI that was asked to sort an array of numbers, and its solution was to delete all the numbers.  
	<br><br>I mostly agree with Shane because currently AIs still resemble computers more than humans. Typically, when you are coding a program, if you are not specific enough, the computer program will not act as you expect, similarly to how AIs act. I believe in the future, AIs will get better at understanding human norms, perhaps by giving them more data on how humans typically respond. However, do we want this behaviour? Human reasoning is often prone to error, is it useful to have an AI that makes the same mistakes as us? Perhaps, it is a good thing that AIs do not behave like us.
	</p>

	<div class="margin"></div>

	<h4 id="forArt">Machine learning failures – for art!</h4>
	<iframe width="600" height="350" src="https://www.youtube.com/embed/yneJIxOdMX4?si=4GQIbOPoDDSxmMmy" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
	<p>In ‘Machine leaning failures – for art!”, Janelle talks about 6 failures that AIs make, specifically for text-generation models. The first one is that they have limited information. Since AIs can only rely on the information they have been given, it is important that they have enough information to be able to generate new output. Another problem is that although AIs can nicely string together words, but it doesn’t know what it is talking about. The third problem is that AIs have limited memory, or “digital amnesia”, as referred to in class. For example, she asked an AI to make a recipe, but after the first couple lines, it forgot what the recipe was originally meant for, and it started giving random instructions. Additionally, Shane mentions that AIs are often under-prepared for the real world. For this failure, she gave an example of an AI model trained to classify My Little Ponies and rock band names. When it was given Star Wars character names, it seemed to randomly classify the characters. The fifth failure is that AIs cannot handle broad questions, but it does do good when there is a clear and narrow problem. This is a problem for cognitive science as our goal is to develop a general intelligence model that can handle multiple different problems, like humans can. Lastly, another failure is that bad training data. AIs need a lot of information, and when they don’t have enough, they cannot do well in novel situations. This can be exploited in image recognition models by adding a bit of noise to an image can drastically negatively impact the performance of the model.
		<br><br>Therefore, in this talk Janelle Shane brings up important issues with current AI, and as cognitive sciences it is imperative that we address them if we want to develop a general intelligence model.	
	</p>

	<div class="margin"></div>

	<h4 id="loveYou">You Look Like a Thing and I Love You </h4>
	<iframe width="600" height="350" src="https://www.youtube.com/embed/2ZiPEOFnK1o?si=CdIf5QTa3ezN3g0Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
	<p>In the video, You Look Like a Thing and I Love You, presented at Google, Shane continues to show her skepticism towards AI. In the beginning of her talk, she points out that AI is often trained and tested with giraffes. As a result, AIs tend to come describe giraffes when they are not there. This showcases the importance of how we train AI with. As cognitive scientists, it is important to find effective ways to train AI that does not lead to bias or errors.
		<br><br>Additionally, she talked about the robot in a human space suit problem. Often companies mislead consumers when they say their project is “AI-powered”, when there is often a human in the background making sure the AI is behaving. For example, some “AI” food delivery companies use an AI robot to deliver food, but a human manually selects each waypoint for the AI and makes sure it is not bumping into anything. In addition, for some “AI” chatbots, a human will take over if the consumer gets angry. These is unethical, because as discussed in class, people have a right to know whether they are interacting with a human or an AI. This also affects the human who is controlling the AI, if people think they are talking to an AI, they are more likely to be rude to them. I believe companies should be more transparent about how they use AI, how they train and test them, and caution users to not fully trust AI.	
	</p>

	<div class="margin"></div>

	<h4 id="revolution">TECHTalk Leading the AI/ML Revolution</h4>
	<iframe width="600" height="350" src="https://www.youtube.com/embed/5Udo-Is3sbQ?si=3cK7CYPVyu0rptJp" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
	<p> TODO
	</p>
	<div class="margin"></div>
  </div>

  <div class="container-fluid margin">
    <h2 class="margin" id="opinion">My Opinion</h2>
    <p>Janelle Shane is a cognitive digital celebrity because she helps increase the public’s knowledge about AI, particularly about its short comings. Her work relates to cognitive science as she compares responses from AI to how humans would typically respond. She tries to train her models to solve problems as a human would, but often she gets weird and creative responses. She also tries to figure out the limits of AI models and how they perceive language. For example, in one of her videos, she mentioned the giraffe problem in AI. She found that when she presented pictures with no giraffes to an AI, it would always say that there is at least one giraffe. She reasoned the AI was doing this because AIs are often trained to identify giraffes, but they are never taught to not identify giraffes. 
		<br><br>I appreciate Shane’s humorous approach to AI. The media frequently portrays AI as malevolent, and we often warned about potential Terminator scenarios. However, Shane's perspective on AI is much more light-hearted and she demonstrates that currently AI is not really that smart as the media often portrays it to be. However, at the same time, her approach is a bit more pessimistic towards AI, as she believes the abilities of AIs are limited.  I believe she may change her mind in the future as AI gets more advanced, most likely as we give AI more information to train on. For example, in one of her talks, she mentioned that GPT-2 often did not generate much weird responses. This could be because, as mentioned in class by Dr. Robert West, that the GPT family works by predicting the next word, rather than considering the meaning of the statement. By being able to accurately predict the next word, this makes GPT good at stringing together sentences that seem to make sense, even when it sometimes spews out non-sense. In addition, Shane also suggested that GPT has access to lots of information, unlike the previous AIs she has been using in the past. This huge corpus of data allows GPT to make less silly mistakes than most AI models. 
		<br><br>Apart from her views on AI, I do not know much else about her, as she primarily focuses on “AI weirdness” on her blog and social media. I can see why she tries to keep her professional life and personal life separate in the "cogsphere" because it is very hard to have privacy on the internet and she does not want her personal life affecting her work or vice versa.
    </p>
  </div>

  <div class="container-fluid margin">
    <h2 class="margin" id="herBlog">Her Blog</h2>
    <p>
      In her blog, she mostly writes about her experiments where she asks different AI models to generate results given a certain prompt. 
      She analyzes the results to ensure that the AI is generating new ideas and that it is not just repeating the training data.
      If she is unsatisfied with the results, she tries to find better ways to train the AI. The result is creative responses from an AI. 
      <br> 
    <p>You can read her blog here!</p>
    <iframe  width="600" height="500" src="https://www.aiweirdness.com/" title="Blog" frameborder="0"></iframe>
  </div>

  <div class="container-fluid margin">
    <h2 class="margin" id="references">References</h2>
    <p>Shane, J. (2023). <em>AI Weirdness</em>. Ghost. <a href="https://www.aiweirdness.com/">https://www.aiweirdness.com/</a><br><br>
    TED. (2019, Nov. 13). <em>The danger of AI is weirder than you think | Janelle Shane.</em> [Video]. YouTube. <a href="https://www.youtube.com/watch?v=OhCzX0iLnOc">https://www.youtube.com/watch?v=OhCzX0iLnOc</a>
    <br><br>
    Note: ChatGPT was used to improve the grammar for this project, with the given prompt, "Improve grammar: ...." 
    </p>
  </div>

<script>
  let mybutton = document.getElementById("backToTop");

  // When the user scrolls down 20px from the top of the document, show the button
  window.onscroll = function() {scrollFunction()};

  function scrollFunction() {
    if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
      mybutton.style.display = "block";
    } else {
      mybutton.style.display = "none";
    }
  }

  // When the user clicks on the button, go to top
  function topFunction() {
    document.body.scrollTop = 0;
    document.documentElement.scrollTop = 0;
  }
</script>
</body>
</html>
